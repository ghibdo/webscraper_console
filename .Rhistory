data<-read.csv(file.choose(), header=F)
iris
clear
view(iris)
View(iris)
mean(iris$Sepal.Length)
mark<-read.csv(file.choose(), header = F)
View(mark)
mean(mark)
mean(mark,v1)
mean(v1)
mean(mark$V1)
mean$V1)
mean($V1)
mean
mark->mean(v1)
mark$V1
mark[,v1]
mark[,V1]
mark(,V1)
mark[1,]
mean(mark[,1])
with(mark,mean[,1])
with(mark,mean(V1))
feature<-read.csv(file.choose(), header = F)
View(feature)
feature<-read.csv(file.choose(), header = F)
feature<-read.csv(file.choose(), header = T)
cls()
sam<-sample(seq(1, nrow(data),10,replace = r))
sam<-sample(seq(1, nrow(data),10,replace=r))
sam<-sample(seq(1, nrow(data),10,replace=T))
sam<-sample(seq(1, nrow(feature),10,replace=T))
data<-read.csv(file.choose(), header = T)
View(data)
View(data)
sam<-sample(seq(1, nrow(data),10,replace=T))
sam<-sample(seq(1,nrow(data),10,replace=T))
sam<-sample(seq(1,nrow(data)),10,replace=T))
sam<-sample(seq(1,nrow(data)),10,replace=T)
view(data)
View($sam)
View(sam)
data$amount[18031]
data$amount[sam]
sam
sam<-sample(data$amount,10,replace = T)
store_mean<-rep(0,10000) >
for (k in 1:10000){
+ +
my_sample<-sample(data$amount,100,replace=T) store_mean[k]<-mean(my_sample)
+}
> store_mean<-rep(0,10000) >
> for (k in 1:10000){
+ +
my_sample<-sample(data$amount,100,replace=T) store_mean[k]<-mean(my_sample)
+}
store_mean<-rep(0,10000) >
> for (k in 1:10000){
+ +
my_sample<-sample(data$amount,100,replace=T) store_mean[k]<-mean(my_sample)
+}
store_mean<-rep(0,10000) >
> for (k in 1:10000){
+ +
my_sample<-sample(data$amount,100,replace=T) store_mean[k]<-mean(my_sample)
+}
store_mean<-rep(0,10000)
for (k in 1:10000){
+ +
my_sample<-sample(data$amount,100,replace=T) store_mean[k]<-mean(my_sample)
+}
for (k in 1:10000){
my_sample<-sample(data$amount,100,replace=T) store_mean[k]<-mean(my_sample)
}
for (k in 1:10000){
my_sample<-sample(data$amount,100,replace=T)
store_mean[k]<-mean(my_sample)
}
hist(store_mean)
mean(store_mean)
sd(store_mean)
with(data, hist(amount))
data<-read.csv(file.choose(), header = t)
data<-read.csv(file.choose(), header = T)
data<-read.csv(file.choose(), header = F)
View(data)
is.factor(data[,1] or str(data))
is.factor(data[,1])
is.factor(str(data))
mean(data$V1)
View(data)
mean(data[,1])
sd(data[,1])
quantile(data[,1], 0.75)
quantile(data[,1], 0.5)
quantile(data[,1], 0.25)
is.factor(data[,1])
is.factor(str(data[,1]))
is.factor(str(data))
is.factor(str(data[,2]))
dim(iris)
dim(iris) names(iris)
dim(iris)
names(iris)
View(iris)
fl_data<-iris
View(fl_data)
View(fl_data)
fl_sample<-sample(fl_data$Sepal.Length,150,replace = F)
fl_sample2<-sample(fl_data$Sepal.Length,150,replace = T)
fl_sample<-sample(fl_data$Sepal.Length,150,replace = T)
mean(fl_sample)
mean(fl_sample2)
sepal_length_ob<-sample(seq(1,nrow(iris$Sepal.Length)),150,replace=T)
sepal_length_ob<-sample(seq(1,ncol(iris$Sepal.Length)),150,replace=T)
sam<-sample(seq(1,nrow(iris)),10,replace=T)
sam<-sample(seq(1,ncol(iris)),10,replace=T)
sam<-sample(seq(2,ncol(iris)),10,replace=T)
sam<-sample(seq(2,ncol(iris$Sepal.Length)),10,replace=T)
sam<-sample(seq(1,ncol(iris$Sepal.Length)),10,replace=T)
data<-read.csv("features.csv", header=T)
data<-read.csv(file.choose(), header = t)
data<-read.csv(file.choose(), header = T)
sam<-sample(seq(1,nrow(data)),10,replace=T)
View(sam)
iris_length<-sample(seq(1,nrow(iris)),150,replace=T)
iris_sample<-iris_length$Sepal.Length
iris_sample<-iris$Sepal.Length[iris_length]
sd(iris_sample)
sd(iris_sample[,1])
mean(iris_sample)
rm(fl_sample)
rm(fl_sample2)
rm(all)
rm(iris_length)
rm(iris_sample)
rm(k)
rm(my_sample)
rm(sam)
rm(store_mean)
rm(data)
rm(feature)
rm(fl_data)
rm(mark)
sample_iris<-sample(seq(1,nrow(iris), 4, replace = T))
rm(sample_iris)
sample_iris<-sample(seq(1,nrow(iris)), 4, replace = T))
sample_iris<-sample(seq(1,nrow(iris)), 4, replace = T)
sample_sepal_length<-iris$Sepal.Length[sample_iris]
store_mean_sepal_length<-rep(0,100)
for (k in 1:100) {
sample_iris_1<-sample(seq(1,nrow(iris)), 4, replace = T)
}
rm(sample_iris_1)
for (k in 1:100) {
sample_iris_1<-sample(seq(1,nrow(iris)), 4, replace = T)
sample_sepal_length_1<-iris$Sepal.Length[sample_iris]
store_mean_sepal_length<-mean(sample_sepal_length_1)
}
for (k in 1:100) {
sample_iris_1<-sample(seq(1,nrow(iris)), 4, replace = T)
sample_sepal_length_1<-iris$Sepal.Length[sample_iris]
store_mean_sepal_length[k]<-mean(sample_sepal_length_1)
}
for (k in 1:100) {
sample_iris_1<-sample(seq(1,nrow(iris)), 4, replace = T)
sample_sepal_length_1<-iris$Sepal.Length[sample_iris]
store_mean_sepal_length[k]<-mean(sample_sepal_length_1)
}
View(store_mean_sepal_length)
store_mean_sepal_length
for (k in 1:100) {
sample_iris_1<-sample(iris$Sepal.Length,4,replace = T)
store_mean_sepal_length[k]<-mean(sample_iris_1)
}
sample_iris_1<-sample(iris$Sepal.Length,4,replace = T)
sample_iris_1<-sample(iris$Sepal.Length,4,replace = T)
sample_sepal_length_1<-sample(iris$Sepal.Length,4,replace = T)
sample_sepal_length_1
for (k in 1:100) {
sample_iris_1<-sample(iris$Sepal.Length,4,replace = T)
store_mean_sepal_length[k]<-mean(sample_iris_1)
}
store_mean_sepal_length
mean(store_mean_sepal_length)
for (k in 1:100) {
sample_iris_1<-sample(iris$Sepal.Length,4,replace = T)
store_mean_sepal_length[k]<-mean(sample_iris_1)
}
sd(store_mean_sepal_length)
mean(iris$Sepal.Length)
sd(iris$Sepal.Length)
sd(iris$Sepal.Length)
mean(iris$Sepal.Length)
sd(iris$Sepal.Length)
view(iris)
View(iris)
with(mean(iris$Sepal.Length))
rm(sample_iris, sample_iris_1)
rm(sample_sepal_length, sample_sepal_length_1, store_mean_sepal_length)
iris_length = iris$Sepal.Length
rm(iris_length)
x<-c(1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 7)
rm(x)
rm(k)
exam_scores = read.csv(file.choose(), header = F)
View(exam_scores)
hist(exam_scores[,1],breaks=seq(120,200,by=10), col="red",
xlab="Exam Scores", ylab="Frequency", main="Exam Score Histogram")
plot(ecdf(exam_scores[,1]), verticals= TRUE,
do.p = FALSE,
main ="ECDF for Exam Scores", xlab="Exam Scores", ylab="Cumulative Percent")
x<-c(1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 7)
plot(ecdf(x[,1]), verticals= TRUE,
do.p = FALSE,
main ="ECDF for Exam Scores", xlab="Exam Scores", ylab="Cumulative Percent")
plot(ecdf(x[,1]), verticals= TRUE,
do.p = FALSE,
main ="ECDF for Exam Scores", xlab="Exam Scores", ylab="Cumulative Percent")
plot(ecdf(exam_scores[,1]),
verticals= FALSE,
do.p = FALSE,#no bullet points
main ="ECDF for Exam Scores",
xlab="Exam Scores", ylab="Cumulative Percent")
more_exam_scores<-read.csv(file.choose(),header=F)
more_hist<- hist(more_exam_scores[,1], breaks=seq(100,200,by=10),plot=FALSE)
orig_hist<- hist(exam_scores[,1], breaks=seq(100,200,by=10),plot=FALSE)
plot(c(100, more_hist$mids, 200),
c(0, more_hist$counts/dim(more_exam_scores)[1], 0), pch=19,xlab="Exam Scores",
ylab="Relative Frequency",main="Relative
Frequency Polygons",ylim=c(0,.30))
lines(c(100, more_hist$mids, 200),
c(0, more_hist$counts/dim(more_exam_scores)[1], 0))
points(c(100, orig_hist$mids, 200),
c(0, orig_hist$counts/dim(exam_scores)[1],
0),col="blue",pch=19)
lines(c(100, orig_hist$mids, 200),
c(0, orig_hist$counts/dim(exam_scores)[1], 0),
col="blue",lty=1)
legend(110,.25,c("Exam 2","Exam 1"), col=c("black","blue"),lty=c(2,1),pch=19)
library("reticulate")
install.packages("reticulate")
use_python("/usr/local/bin/python3.9", required = T)
py_config()
library("reticulate")
use_python("/usr/local/bin/python3.9", required = T)
py_config()
rm(exam_scores, more_exam_scores, more_hist, orig_hist)
rm(x)
set.seed(99)
for (k in 1:10000){
my_sample<-sample(data$amount,4,replace=T) #takes a random sample of 4
store_mean[k]<-mean(my_sample)
}
rm (k)
View(iris)
#if population = Sepal.length
mean(iris$Sepal.Length)
hist(iris$Sepal.Length)
set.seed(99)
for (k in 1:10000){
my_sample<-sample(data$amount,4,replace=T) #takes a random sample of 4
store_mean[k]<-mean(my_sample)
}
set.seed(99)
for (k in 1:10000){
my_sample<-sample(data$amount,4,replace=T)
store_mean[k]<-mean(my_sample)}
for (k in 1:10000){
my_sample<-sample(iris$Sepal.Length,4,replace=T)
store_mean[k]<-mean(my_sample)
}
store_mean<-rep(0,10000)
for (k in 1:10000){
my_sample<-sample(iris$Sepal.Length,4,replace=T)
store_mean[k]<-mean(my_sample)
}
hist(store_mean)
for (k in 1:50){
my_sample<-sample(iris$Sepal.Length,36,replace=T)
store_mean[k]<-mean(my_sample)
}
hist(store_mean)
store_mean_2<-rep(0,50)
for (k in 1:50){
my_sample<-sample(iris$Sepal.Length,36,replace=T)
store_mean_2[k]<-mean(my_sample)
}
hist(store_mean_2)
rm(store_mean_2)
exam_scores = read.csv(file.choose(), header = F)
exam_scores<-read.csv(file.choose(), header = F)
plot(ecdf(exam_scores[,1]))
verticals = TRUE, do.p = FALSE,
main = "ECDF for exam score",
xlab="Exam Scores",
ylab="Cumulative Percent",
plot(ecdf(exam_scores[,1]))
verticals = TRUE,do.p = FALSE,
main = "ECDF for exam score",
xlab="Exam Scores",
ylab="Cumulative Percent",
xlim=c(100,200))
plot(ecdf(exam_scores[,1]),
verticals= TRUE,do.p = FALSE,
main ="ECDF for Exam Scores",
xlab="Exam Scores",
ylab="Cumulative Percent",
xlim=c(100,200))
dim(cars)
View(dim(cars))
View(cars)
mean(cars$dist)
sd(cars$dist)
hist(cars$dist)
cars_dist_samp<-sample(cars$dist,16,replace=T)
cars_dist_samp
store_car_mean<-<-rep(0,1000)
store_car_mean<-rep(0,1000)
store_car_sd<-rep(0,1000)
for (k in 1:1000){
new_car_sample<-sample(cars$dist,16,replace=T)
store_car_mean[k]<-mean(my_sample)
}
mean(store_car_mean)
sd(store_car_mean)
for (k in 1:1000){
new_car_sample<-sample(cars$dist,16,replace=T)
store_car_mean[k]<-mean(new_car_sample)
}
mean(store_car_mean)
sd(store_car_mean)
hist(store_car_mean)
####homework 2
ages<-c(19,23,30,30,45,25,24,20)
sd(ages)
mean(ages)
new_age = ages+10
quantile(new_age, 0.25)
sd(new_age)
mean(new_age)
oh_house_data<-read.csv(file.choose(), header = F)
mean(oh_house_data)
mean(oh_house_data$V1)
mean(oh_house_data[,1])
median(oh_house_data$V1)
hist(oh_house_data)
hist(oh_house_data$V1)
median(oh_house_data$V1 + 10)
median(oh_house_data$V1 * 2)
x<-10
new_oh_data<-c((oh_house_data$V1[1:x]+2900),oh_house_data$V1[x:length(oh_house_data$V1)]
)
view(new_oh_data)
View(new_oh_data)
View(new_oh_data$V1)
new_oh_data
rm(new_oh_data)
new_oh_data<-oh_house_data
new_oh_data[1:10]<-(oh_house_data$V1[1:10]+29000)
rm(new_oh_data)
new_oh_data<-oh_house_data
new_oh_data$V1[1:10]<-(oh_house_data$V1[1:10]+29000)
median(new_oh_data$V1)
mean(new_oh_data$V1)
rm(ages)
ages<-c(19,23,30,30,45,25,24,20)
ages<-(ages*100)
sd(ages)
setwd("~/PycharmProjects/webscraper_bal_sheet")
library("reticulate")
use_python("/usr/local/bin/python3.9")
py_config()
import("pandas")
import("lxml")
import("bs4")
import("requests")
py_run_file("main.py")
console_sales_NA<-py$df
library(ggplot2)
p<-console_sales_NA %>%
gather("Country", "Sales",-Console) %>%
ggplot(aes(Console, as.numeric(Sales), fill = Country)) +
geom_bar(position = "dodge", stat = "identity",color="black")+
labs(y = "Sales in Millions") +
scale_y_continuous(breaks = seq(0, 160, by = 10))+
theme_bw()
p
library(tidyr)
setwd("~/PycharmProjects/webscraper_bal_sheet")
library("reticulate")
use_python("/usr/local/bin/python3.9")
py_config()
import("pandas")
import("lxml")
import("bs4")
import("requests")
py_run_file("main.py")
console_sales_NA<-py$df
library(tidyr)
library(ggplot2)
p<-console_sales_NA %>%
gather("Country", "Sales",-Console) %>%
ggplot(aes(Console, as.numeric(Sales), fill = Country)) +
geom_bar(position = "dodge", stat = "identity",color="black")+
labs(y = "Sales in Millions") +
scale_y_continuous(breaks = seq(0, 160, by = 10))+
theme_bw()
p
